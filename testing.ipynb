{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from model.layers import Embedding, Sigmoid, Softmax, Linear, BCELossWithSigmoid\n",
    "from model.HS_model import HS_skipgram\n",
    "from preprocess import *\n",
    "from optim.optimizer import SGD\n",
    "from itertools import repeat\n",
    "import time\n",
    "import pickle\n",
    "from eval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from collections import Counter\n",
    "from fuel.utils import find_in_data_path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Huffman_Tree: 100%|████████████████████████████████████████████████████████| 692000/692000 [00:02<00:00, 268725.54it/s]\n",
      "Padding Paths: 100%|███████████████████████████████████████████████████████| 692001/692001 [00:01<00:00, 563190.40it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 300\n",
    "sample_size = 5\n",
    "path = \"./data/text8.txt\"\n",
    "\n",
    "path = \"./1-billion-word/training-monolingual.tokenized.shuffled\"\n",
    "\n",
    "with open(\"./data.pickle\", 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "\n",
    "word2idx = save[\"word2idx\"]\n",
    "idx2word = save[\"idx2word\"]\n",
    "count = save[\"count\"]\n",
    "file_path = save[\"file_path\"]\n",
    "\n",
    "node, max_depth = Huffman_Tree(count)\n",
    "\n",
    "\n",
    "def batch_words(paths):\n",
    "    words = []\n",
    "    for path in paths:\n",
    "        word = recall_word(path)\n",
    "        words += word\n",
    "\n",
    "    return words\n",
    "\n",
    "#sample_size random하게 바꿈. --> 한 corpus에서 더 다양하게 보는게 가능!\n",
    "model = HS_skipgram(len(word2idx), 300, lr = 0.0025)\n",
    "criterion = BCELossWithSigmoid()\n",
    "optimizer = SGD(lr = 0.0025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at\n",
      "Tuesday 0.4225332\n",
      "Saturday 0.42261708\n",
      "Monday 0.4307065\n",
      "Wednesday 0.43971354\n",
      "it\n",
      "that 0.5832618\n",
      "but 0.59210306\n",
      "he 0.60609686\n",
      "not 0.6258452\n",
      "by\n",
      "Mr 0.39092788\n",
      "has 0.3986169\n",
      "from 0.4230901\n",
      "also 0.42829302\n",
      "from\n",
      "after 0.3988304\n",
      "down 0.3991226\n",
      "while 0.41642633\n",
      "by 0.42309004\n",
      "be\n",
      "them 0.49952155\n",
      "if 0.49970323\n",
      "get 0.5067466\n",
      "make 0.51498616\n",
      "have\n",
      "'ve 0.5059802\n",
      "were 0.51417613\n",
      "had 0.536062\n",
      "they 0.5764618\n",
      "he\n",
      "him 0.5341303\n",
      "He 0.6044412\n",
      "it 0.60609674\n",
      "she 0.76515114\n",
      "has\n",
      "have 0.46257162\n",
      "been 0.47378683\n",
      "since 0.5046708\n",
      "had 0.5946984\n",
      "his\n",
      "himself 0.42631227\n",
      "career 0.43035465\n",
      "him 0.50519264\n",
      "her 0.6237497\n",
      "are\n",
      "some 0.55707526\n",
      "were 0.558606\n",
      "those 0.56443673\n",
      "these 0.5952014\n"
     ]
    }
   ],
   "source": [
    "def evaluate(path, model, word2idx, idx2word):\n",
    "    with open(\"./bestmodel.pickle\", 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "\n",
    "\n",
    "    model.params = x\n",
    "    for i in range(20,30):\n",
    "        #ex = np.random.choice(len(word2idx), 1)[0]\n",
    "        model.query(idx2word[i], word2idx, idx2word, top = 4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "evaluate(\"\",model,word2idx, idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./bestmodel.pickle\", 'rb') as f:\n",
    "    x = pickle.load(f)\n",
    "\n",
    "\n",
    "model.params = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem, syn = test_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scoring: 100%|█████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.06it/s]\n",
      "scoring: 100%|█████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_score(10, sem,syn, model, word2idx, idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.random((10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((2,10)).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[a].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Athens', 'Greece', 'Baghdad', 'Iraq'],\n",
       "       ['Athens', 'Greece', 'Bangkok', 'Thailand'],\n",
       "       ['Athens', 'Greece', 'Beijing', 'China'],\n",
       "       ...,\n",
       "       ['uncle', 'aunt', 'stepbrother', 'stepsister'],\n",
       "       ['uncle', 'aunt', 'stepfather', 'stepmother'],\n",
       "       ['uncle', 'aunt', 'stepson', 'stepdaughter']], dtype='<U13')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uninformed\n",
      "Polish\n",
      "smaller\n",
      "Egyptian\n",
      "best\n",
      "predicted\n",
      "hands\n",
      "quietly\n",
      "running\n",
      "stronger\n",
      "Somalia\n",
      "Nigeria\n",
      "Sudan\n",
      "France\n",
      "Nicaragua\n",
      "Syria\n",
      "Turkey\n",
      "Pakistan\n",
      "Switzerland\n",
      "Cuba\n"
     ]
    }
   ],
   "source": [
    "sample = 10\n",
    "def statement(query):\n",
    "    for word in query:\n",
    "        if word not in word2idx:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "semc = sem[np.random.choice(len(sem), sample)]\n",
    "sync = syn[np.random.choice(len(syn), sample)]\n",
    "\n",
    "W_in , _ = model.params\n",
    "score = [0,0]\n",
    "\n",
    "for i,sort in enumerate([sync, semc]):\n",
    "    test = np.zeros((sample, 300))\n",
    "    for j,query in enumerate(sort):\n",
    "        if statement(query):\n",
    "            continue\n",
    "        # 1 - 0 + 2 = 3\n",
    "        query_vec = W_in[word2idx[query[1]]] - W_in[word2idx[query[0]]] + W_in[word2idx[query[2]]]\n",
    "        test[j,:] = query_vec\n",
    "    \n",
    "    #오름차순에 의해 정렬\n",
    "    similarity = cosine_similarity(W_in , test)\n",
    "    result = similarity.argsort()[:,-5:]\n",
    "    for idx, ans in zip(result, sort[:,3]):\n",
    "        if statement([ans]):\n",
    "            continue\n",
    "        print(ans)\n",
    "        if word2idx[ans] in idx:\n",
    "            score[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 72, 71, ..., 26, 36, 99],\n",
       "       [ 0, 72, 71, ..., 26, 36, 99],\n",
       "       [ 0, 72, 71, ..., 26, 36, 99],\n",
       "       ...,\n",
       "       [ 0, 72, 71, ..., 26, 36, 99],\n",
       "       [ 0, 72, 71, ..., 26, 36, 99],\n",
       "       [ 0, 72, 71, ..., 26, 36, 99]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t / np.linalg.norm(t, axis = 1, keepdims = True)).argsort(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
